{% extends "layout.html" %}
<title>
{% block title %}Model used: convolutional neural network {{ super() }}{% endblock %}
</title>
{% block content %}
{{ super() }}

<div id=model class="container-fluid bg-grey">
    <div class="col-sm-8">
        <h2>Model</h2>
        <p>
        A Convolutional Neural Network (CNN) with 3 layers was trained to perform image recognition.
        </p>
        <h2>Training</h2>
        The model is trained with about 6k images of different types of food, namely
        {% for key, value in food.items()%} {{key|e}},{%endfor%}
        (this limits what the model can identify in the picture you upload).
        The sample was cleaned up manually in order to select only images which clearly show each food
        without other objects in the image. This improves the performance substantially.
        A validation sample was used to test the accuracy and loss reached during the training.
        </p>
        <h2>Performance</h2>
        The accuracy of the model reaches 75% on the validation sample.
        <div class="thumbnail">
            <img src="static/performance_model_Y5pat_tr3110_4noneg_v917_4noneg_steps_per_epoch_40_epochs_20_validation_steps_10.jpg" alt="accu" size="float:right;width:50px;">
            <p><strong>Accuracy and loss on the training and validation samples.</strong></p>
        </div>
        <p>The loss is around 0.7 with large fluctuations.
        Training on more epochs overfits the model.
        The confusion matrix allows to see how the false positive/negatives are
        distributed among the different classes.
        </p>
        <div class="thumbnail">
            <img src="static/confusion_matrixPlaceholder.jpg" alt="ConfusionMatrix" size="float:right;width:50px;">
            <p><strong>Confusion matrix of the test set (TO BE UPDATED)</strong></p>
        </div>
        <p>A cutoff on the probability is applied and no answer is given if any of the classes
        scores a probability of at least 80%. This assures also that food items
        not belonging to the training are not classified.
        The obvious improvement to be foresee is to increase the number of classes.
        </p>
        <h2>Next steps</h2>
        <p>
        The original goal of the capstone project was to recognize food items in a "complex" image,
        where more food items are present (for instance from a picture of the fridge).
        The following steps were the recommendation of a list of receipes with the ingredients
        found in the picture and/or the determination of the ingredients missing from a receipe provided
        by the end user.
        The actual functionality of the app is limited to recognizing simple images
        (with only one food item) and provide external links to the search on the
        Giallo Zafferano web page.
        </p>
        <p>
        The use of complex images was attempted by using the selection of regions in
        the figure using OpenCV. The region proposal as is was not accurate enough.
        </p>
        <h2>Academic works on the same topic</h2>
        There are several works aimed at recommending receipes connecting information
        on calories and using image recognition to identify the ingredients.

    </div>

    <div class="col-sm-4">
        <div class="thumbnail">
            <img src="static/model_3cl_do20_tr6400_5_v1343_5_steps_per_epoch_100_epochs_20_validation_steps_10.png
" alt="Model">
            <p><strong>Schema of the CNN</strong></p>
        </div>
    </div>


</div>

{% endblock content %}